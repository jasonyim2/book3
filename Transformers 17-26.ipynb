{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [
        {
          "file_id": "1hcJkcxDH0A2yNCJ0EuitC1ycrvffOwUQ",
          "timestamp": 1667701126583
        }
      ],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_0ZD-UAQ-hiW"
      },
      "source": [
        "# 17"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 938,
          "referenced_widgets": [
            "7116aa8568334af0a622c4c7237ac76b",
            "fedd99d5bbb94d5d9de9aedaebe2a03f",
            "657ae1754c4b4447bc85742d22e83c9a",
            "239114c95636426d93709966ff2ffdc4",
            "7b9f6faec00f4147a583abcb58e2e932",
            "81e1d268506a4cf9a9c8e2c8bc448d0e",
            "6a76a28e271d42789e49095077035899",
            "70196272e6a14eeda421d5e6c7a98ff6",
            "2baf13c268104f99902cec800400ee09",
            "9532b5bda46e419d83fccd6a5448bcb5",
            "16e8d8d1e655497d868e26cfcf10055f",
            "33c44269b9b84d5b9b25b94c20c01c55",
            "b672ba374c9d4bbaa39a3db1196d7c4a",
            "1e4e3c60e83c490a8d4de03933557a34",
            "c5ab1a2110c84c98b652d4acbbc42dc3",
            "179a3b0f36834f73998a526f0035781c",
            "d3d5cd810b72452c82971a99ebeecdb0",
            "23b47e1d85164dc4baf5e2029051e301",
            "f4e07c951ee04e4da973b8841d00652a",
            "4b851d9581a6400a84abc0e88d32a3f9",
            "da58cd6c4ece46128b9b2f0bf8c82acd",
            "a1e88998a7a94168b11401aef4466713",
            "75e9dbdc6a224d53bbfebb99baf306fe",
            "626e96f9d01249f18bd62cd42226dfcc",
            "1f83047a46b7451a99560dfec01f4ec4",
            "fe57ca434b714c93bb93a6c1434ce3ef",
            "9d24b9f5e1a94ea4bdc9421caae88243",
            "2021841ef304440fa1e33fbffaef0f96",
            "e7ed179e0a4d409aae510825c573df39",
            "0b215d3a0d614d77b4d1bd2afd8a3c01",
            "f591210fd85841248095db3d43d57b70",
            "daa272afc9034bbb97fb112fe9237107",
            "b5e86ae9253d4716851a26ea1f1b3c9e",
            "d7d9e0c7f94c4ac39598f0063db533e3",
            "e7a302df436f4105a3e214626e271ac8",
            "f126e3da41d64200b7c88fa2926c2768",
            "fa82969a93e248e090ddfdff9de586bb",
            "2b58441e8322450c8c46ebed9d5e9393",
            "5f5f4c3daee642f0879b840052b2b28f",
            "d0756da2bb86498fa5f8fe94beeedacb",
            "e9a228884aed4198b3ea5a862472f7d2",
            "c7dfc9d7751645a8a47cb2afa1ee3016",
            "18b1f19087294bc6bce4c39f5bd8e484",
            "0b646be7d88a44b5829484e57ffab332",
            "598687be02b34972bbe418c22930c800",
            "fbd792a4383d47c0b28f601b1e5a2c65",
            "1a93ef67ccdb424585de0b570e94f66a",
            "32484fccef504d82bc193ed720b8cd91",
            "a0ac42a8907543989e4e7997b11519dd",
            "342b0dca203445d58c24ce7d91d28e5f",
            "b2542acb91ca40a2afabf4f3168c5d3b",
            "b71c6e45e517442fb4eae8915ad44286",
            "8b1be0dbd75344e9a51421e3e163d42e",
            "00778132307e4ab582d85c7f8fc7880a",
            "42abdf9ac5b8489c98932e3860a0c4fe",
            "b45b2a039fc6411b9e0e4dc702f5d483",
            "7ffe28e166cb4eda9312401bac7275b7",
            "62a6b497e9d240b4a25fc984304b1b19",
            "9bb215ef76714dce93218a1448f27b51",
            "7c18e27cb38b4a838759a3ea4836dfc3",
            "62cdc937a05a44c5908ace32b7bc6752",
            "7cf1a722a98d459eb2d853f353b2d453",
            "70d2c28b379940b4b3cba70aa30d5dc0",
            "67978588d8b84f6ea8b986366da80266",
            "ce1d70e762634747b9caa04f5866fcbf",
            "3893237ddfa149ce89e3e3a08b8eed1f"
          ]
        },
        "id": "ksjIEhFFAFLD",
        "executionInfo": {
          "elapsed": 99755,
          "status": "ok",
          "timestamp": 1688436186201,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "188c48ef-ebe2-4f97-aadb-60cf6276381f"
      },
      "source": [
        "# 런타임 3분 소요\n",
        "!pip install transformers sentencepiece\n",
        "from transformers import GPTNeoForCausalLM, GPT2Tokenizer\n",
        "\n",
        "# 모델 및 토크나이저 불러오기\n",
        "model = GPTNeoForCausalLM.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")\n",
        "tokenizer = GPT2Tokenizer.from_pretrained(\"EleutherAI/gpt-neo-1.3B\")"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m97.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m78.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m32.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m63.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m84.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, sentencepiece, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 sentencepiece-0.1.99 tokenizers-0.13.3 transformers-4.30.2\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/1.35k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7116aa8568334af0a622c4c7237ac76b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/5.31G [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "33c44269b9b84d5b9b25b94c20c01c55"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/798k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "75e9dbdc6a224d53bbfebb99baf306fe"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d7d9e0c7f94c4ac39598f0063db533e3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)cial_tokens_map.json:   0%|          | 0.00/90.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "598687be02b34972bbe418c22930c800"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/200 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "b45b2a039fc6411b9e0e4dc702f5d483"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dTmxkzQiDihD"
      },
      "source": [
        "#18"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-YFr7Z5xesyK",
        "executionInfo": {
          "elapsed": 5504,
          "status": "ok",
          "timestamp": 1688436215481,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "a61cd44a-5c5c-4525-adda-74d6b362d597"
      },
      "source": [
        "# 토크나이징을 통한 인코딩(입력문이 하나인 경우)\n",
        "input = tokenizer.encode(\"I evaluated the performance of GPT-Neo developed by OpenAI.\", return_tensors=\"pt\")\n",
        "\n",
        "# 첫번째 인코딩 결과(결과적으로 하나의 입력문장)를 확인\n",
        "print(input[0])\n",
        "\n",
        "# 첫번째 인코딩 결과를 디코딩\n",
        "print(tokenizer.decode(input[0]))\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
            "         4166,   416,  4946, 20185,    13])\n",
            "I evaluated the performance of GPT-Neo developed by OpenAI.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cLfNYeLLB41-",
        "executionInfo": {
          "elapsed": 454,
          "status": "ok",
          "timestamp": 1688436218941,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "b6a79a10-0b52-42c7-a57e-386a9062e7cb"
      },
      "source": [
        "# 토크나이징을 통한 인코딩(입력문이 복수인 경우)\n",
        "tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "\n",
        "input = tokenizer.batch_encode_plus([\"I evaluated the performance of GPT-Neo developed by OpenAI.\",\"I evaluated the performance of GPT developed by OpenAI.\"], padding=True, truncation=True, return_tensors=\"pt\")\n",
        "\n",
        "# 인코딩 결과 확인\n",
        "print(input['input_ids'])\n",
        "\n",
        "# 디코딩\n",
        "print([tokenizer.decode(input['input_ids'][i]) for i in range(len(input['input_ids']))])\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[   40, 16726,   262,  2854,   286,   402, 11571,    12,  8199,    78,\n",
            "          4166,   416,  4946, 20185,    13],\n",
            "        [   40, 16726,   262,  2854,   286,   402, 11571,  4166,   416,  4946,\n",
            "         20185,    13, 50257, 50257, 50257]])\n",
            "['I evaluated the performance of GPT-Neo developed by OpenAI.', 'I evaluated the performance of GPT developed by OpenAI. [PAD] [PAD] [PAD]']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dE9Vi3MQDgj8"
      },
      "source": [
        "# 19"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uMW7GPyWCE5T",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688436227308,
          "user_tz": -540,
          "elapsed": 970,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        }
      },
      "source": [
        "# 토크나이징\n",
        "input = tokenizer.batch_encode_plus([\"I evaluated the performance of GPT2 developed by OpenAI.\", \"Vaccine for new coronavirus in the UK\",\"3.1415926535\"], max_length=5, truncation=True, padding=True, return_tensors=\"pt\")"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pzWXx080EDM6",
        "executionInfo": {
          "elapsed": 3,
          "status": "ok",
          "timestamp": 1688436230743,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "1435a44a-b5cf-47c4-8987-be9473a376d6"
      },
      "source": [
        "# 인코딩 결과 확인\n",
        "input['input_ids']"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[   40, 16726,   262,  2854,   286],\n",
              "        [   53,  4134,   500,   329,   649],\n",
              "        [   18,    13,  1415, 19707, 22980]])"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rfgYP8tUE4zF",
        "executionInfo": {
          "elapsed": 12018,
          "status": "ok",
          "timestamp": 1688436246452,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "9dcd6650-e226-4c02-ae2a-4e4eb0823e4e"
      },
      "source": [
        "# 인코딩 결과를 model.generate( )에 투입\n",
        "generated = model.generate(input['input_ids'])"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "/usr/local/lib/python3.10/dist-packages/transformers/generation/utils.py:1353: UserWarning: Using `max_length`'s default (20) to control the generation length. This behaviour is deprecated and will be removed from the config in v5 of Transformers -- we recommend using `max_new_tokens` to control the maximum length of the generation.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KIK9Hli6GBp4",
        "executionInfo": {
          "elapsed": 474,
          "status": "ok",
          "timestamp": 1688436250248,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "211fac22-57d2-4e9c-cb86-95fe1899e836"
      },
      "source": [
        "# model.generate( ) 결과 건수(len) 확인\n",
        "len(generated)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VXk4G7ebDnWN",
        "executionInfo": {
          "elapsed": 451,
          "status": "ok",
          "timestamp": 1688436257923,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "fb6da9f6-1528-451f-d7f3-501ea4e2414f"
      },
      "source": [
        "# 디코딩\n",
        "generated_text = tokenizer.batch_decode(generated)\n",
        "\n",
        "# enumerate( )는 변수 generated_text에 있는 키값(value)에\n",
        "# 0, 1, 2,...로 시작하는 숫자 키(key)를 부여\n",
        "for i, sentence in enumerate(generated_text):\n",
        "  print(f'No.{i+1}')\n",
        "  print(f\"{sentence}\\n\")\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "No.1\n",
            "I evaluated the performance of the proposed method on the real-world dataset. The results are shown in\n",
            "\n",
            "No.2\n",
            "Vaccine for new-borns\n",
            "\n",
            "The vaccine for new-borns is a vaccine\n",
            "\n",
            "No.3\n",
            "3.1415926535897932384626433832795028841971693\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yP2lNBQTHopr"
      },
      "source": [
        "# 20"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 433,
          "referenced_widgets": [
            "50074639706c4556a44de85e0a661cbb",
            "3e385b4f2e1845f7ae136a171b90fb8f",
            "b4820a6c1be24b919d3a0d70c3b34913",
            "7790c325654e4e429b200dd98cca9bfa",
            "4f2b94e4c2934154ba5d20526a7d074f",
            "cf891c8c537342eeb6f59aab1e6c8131",
            "c821ea0852094622a4ded4526a1e6de1",
            "1afeb54eedb24eed85a9d9a1b15904a7",
            "55c957c3d8c9440fb9eff148a9c40492",
            "93b59eb7958f434fbb3031a2e9fb80aa",
            "d3a95821a9294673aa8a48a6191bb499",
            "85e8514a430148638c443276b8c105e9",
            "3b00b721a4d3463dbab0e863bd83b57b",
            "1f2efddd82ec4ac896b7cabe3e083855",
            "03b5895f4cd44457aa8b38d59ecbb39a",
            "17295b4a2b38419a94bab9476d0f8688",
            "dbdc4ec1bc1a4774b5b7ddc85a04002d",
            "410bd82eda2643a3a29d376bf0524177",
            "34e2217a107244f89f3018ccab36cb19",
            "1c080b78e91f4d75b4a8f1803ae2c7f8",
            "c02ad732f56a492c85ad46f8eba3ab6d",
            "de5e23a350cb4fe7b589b3e997ed04f1",
            "4213e83108044c5b83e009df91e2cdb3",
            "1c56a7194313463da574484c2a0b063c",
            "18c383c75ba54490b92756b0040525ab",
            "58515d941de74418927f5d97a525fff8",
            "f8366d3cc0544bffac357342e5e2a04a",
            "f4377c2aceba4ea6a864bc704e1d9b97",
            "b9b70ed8b05848469e97f28c8e70ea41",
            "7c0f76f4b79d488c846d9cb4412ab57a",
            "2f7093aa2684429cafb6e89b18beb524",
            "2b3e7026c8e74e0aa430e2017a8ba457",
            "6f6b52db97594c59bc5384aed539be64",
            "c84f997716674805b19a50dce9c14f3f",
            "0dd968ebbfbf4cf4b76c7f2d557d5fd5",
            "a59c5a3caaf9470688d063b3300314b6",
            "b1982d95fbcc4df3bbac877e955e0678",
            "237c84ec55bf4916886b03cf06640b5d",
            "f422dd65b703468b9f314e81ee9e30d8",
            "cf911298e0bf4524b823b6c8448af67f",
            "22062092332143b6bed859a3db62f6fe",
            "4bfb673095284329b50d4ac33d6d82e0",
            "2dd87fc7201441639acbb26aece3103b",
            "3f1224e5c24e40d1876cd84eafd02b45",
            "3e288867f3b641cebff5de91d61cb18d",
            "efbdf16476014589a0cf5340baf2b037",
            "82594432b5fe40b096bef9826dc37bc6",
            "d6f428338e2e42e3a4a7ba25d8f00d2e",
            "62e7d3b34f964132aa115539417882da",
            "8ae298b9b97840678aca2e589264280a",
            "613fdeed11dd40c19323fcd1a7c165ff",
            "8e21985808094c13b49a04a2e63df65b",
            "eedfca3b28e748b0b7b9735f82da48e8",
            "f4805a9211674d3387a6f08d02c52338",
            "11aec0b01dc94fbaaec2df3557338453",
            "05b1010866444cc1b24a15a8723fbc8a",
            "63a16f64404a4bceb30b7b7024f99e68",
            "7b38322080f945c2a3b9186b1084d7af",
            "00145117b67d44738cd096fb367d795d",
            "5077707c1b5e42bab441ca980d54e1f4",
            "0d46bae0b9a3474ca39b43bdc5af6be3",
            "48a8e166ece649afa2e71798606c797d",
            "4ed8245a24054c6992759b89799bf0d8",
            "5c1c85e94fbc470fb07f938ad5cd64cb",
            "45ab89a083d84fe19c0dff77dd5de106",
            "16803b0f7911487f8b7ef6a8cddbff37"
          ]
        },
        "id": "W-CMslK9F2AE",
        "executionInfo": {
          "elapsed": 10431,
          "status": "ok",
          "timestamp": 1688436277354,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "b1842f90-7f7f-48ef-f1db-99a820d85ea2"
      },
      "source": [
        "# 코랩 메모리가 clear된 경우만 transformers 재설치\n",
        "# !pip install transformers\n",
        "\n",
        "# 모델 및 토크나이저 불러오기\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"distilgpt2\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "50074639706c4556a44de85e0a661cbb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "85e8514a430148638c443276b8c105e9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4213e83108044c5b83e009df91e2cdb3"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c84f997716674805b19a50dce9c14f3f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1362: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3e288867f3b641cebff5de91d61cb18d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "05b1010866444cc1b24a15a8723fbc8a"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "u-n9rtMGIFnq"
      },
      "source": [
        "# 21"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mi1CADfzHqVb",
        "executionInfo": {
          "elapsed": 458,
          "status": "ok",
          "timestamp": 1688436287675,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "bc895d9f-ce4c-456c-cc95-fcd372584232"
      },
      "source": [
        "# 토크나이징. 출력은 파이토치 텐서(pt)로 받음\n",
        "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
        "\n",
        "# max-length 값을 12로 설정\n",
        "greedy_output = model.generate(input_ids, max_length=12)\n",
        "\n",
        "# *표시를 100번 실행하여 *로 구성된 줄 만들기\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "\n",
        "# 인코딩 결과 디코딩\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I like gpt because it's a good thing to have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 22"
      ],
      "metadata": {
        "id": "eoTMp-OztkhO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델 및 토크나어지 불러오기\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377,
          "referenced_widgets": [
            "f9fc6e4ae74d4b2e980583eefe7a6622",
            "0d78fe15128d4095898cc989aadbce1a",
            "c919dd5347dc4f269033135b4e55bb2e",
            "6f75eb72520840e9801520d8194383c0",
            "3d3eeb2a7aae45f3b4e7254f9891046b",
            "6f79648bcf0045f6934a64df4e9c92ab",
            "615cff3eb0674572ba127892a0362dd9",
            "d1ccef509dff43978e3b31d49d00a8f8",
            "26cff237a73448689ade95f69dcb6aa2",
            "d1fa33c3cf8646718ccfdb8b061b727d",
            "a7f15dcc6d2d45a482a9f0535c1cfbe4",
            "3a7ec4566b85459892a15baa715047a7",
            "7da565fac0d34094b7a0e2bdea59ca83",
            "13222274e60347e89ae0eb6928eacd4a",
            "1c3824b62213451ba683d9eb94e04942",
            "bd3a82f2e85945b299fd413f41e4c967",
            "6131787af39d4f8bb2e67fafaed09110",
            "f9042e04274d437c91b969dd2d0cce69",
            "77a72b73607b49db957d00f316f1bacc",
            "ac1dbdb3c3754947a426406bd59c12ec",
            "0a8594cac6d24e86b8db9b4fb7a7a7b7",
            "804850485e60425793e0ad4143af534f",
            "00bff3ad052446f9b2310c2d6764b275",
            "72c75765cca54878adca436c6c7f3461",
            "ee7516581ed14a94a11fac574095f103",
            "44a452ac46ee43029b312a7efa9ffdba",
            "57bd3f04a6704fda83a1cd432538592d",
            "779b140fbf0e41f2b9cee1dbba708fc9",
            "a7293c3ca6954d1bbba68e4a541f4966",
            "96e87e5cdd3746399cf390cddd29cab2",
            "349291b835a646ef8856b38b6f46ff83",
            "a6ac4da532fb460d87e0f4183a59cdba",
            "56f81c92280c4703983ab17a5181bb8b",
            "06fb1d07ee6641c89ad62e6f35c7770b",
            "d69f3dfd15d84f3e96c425df2ec00dda",
            "192697c589444bdcbf4a7676d0a9a759",
            "03f8bc20a4484b0eb7032eac55fda2eb",
            "6e1c9c643795450d8f57f1c69f6240a5",
            "9aebabf7c5744156ad589e97ee0dccfe",
            "a90c184904564be39e7d67b5c08a8059",
            "5750cc5d44c04944879e2ca3f7ab9fb8",
            "ee1dc3cc91054a7690fe2648420622d8",
            "9c936f8202bf4a04b3b7f53c3302ccf4",
            "6c4fbdfd673e4a7eb15295938d445438",
            "6dd599a23b734cca8cb0228b77957dfb",
            "9a20084f43a44f26a200870c1e4a4ebb",
            "889e3cb5359644bcbf3a49de4e3bb1a8",
            "6e8352a3d6f945cb849969f96cb1af3d",
            "05fbebb26c2847f89fcee50add7211b6",
            "171d16195b9d4fbdb2beda906f73f72f",
            "b4bec5e75b674ff2bc374c5e80d2dfcc",
            "3b52e8cb2b084a20ace065fd565aed3a",
            "6a009e4c39a642b4b83fcb0bed2eef33",
            "952d9f0bee834eec921b1bb3afb0150f",
            "d2ee1781bee14ffaacb1c12358469fed",
            "1960125bf978466398f4f9ef8e772fea",
            "477d2b1fad1e4ea49333495fff075a50",
            "30c6907e2ada43f48d9fb9b0109faed5",
            "39821ad3699143d8a6f9a2cfaa6fb76f",
            "b62311a39c344219bb6f9d06c75fd9c1",
            "e23b931634f64bea928f41ab9ba2de1e",
            "149864790ce84d47ab60917961e3afa7",
            "7ef343236b4d459292310964ad7b75e7",
            "df808878600c4e15a0a4e219a77b5e59",
            "677b5fe7eec34d85a22a23f9403904ed",
            "634a27ce0e044b0b81aaad461400ca71"
          ]
        },
        "id": "mfus-Fc2tpjA",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688437530561,
          "user_tz": -540,
          "elapsed": 7545,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "9a97fea1-8831-49f5-de81-f15f3d7bacbf"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "f9fc6e4ae74d4b2e980583eefe7a6622"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "3a7ec4566b85459892a15baa715047a7"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "00bff3ad052446f9b2310c2d6764b275"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "06fb1d07ee6641c89ad62e6f35c7770b"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6dd599a23b734cca8cb0228b77957dfb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "1960125bf978466398f4f9ef8e772fea"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 23"
      ],
      "metadata": {
        "id": "s1PgqpPjuHQe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 토크나이징\n",
        "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
        "\n",
        "# max-length 값을 30으로 설정\n",
        "greedy_output = model.generate(input_ids, max_length=30)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UXwIf3VluSJD",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688437666200,
          "user_tz": -540,
          "elapsed": 936,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "5ac3523b-65e8-4e20-cf87-12738f2f66d8"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I like gpt because it's a good way to get a feel for the game.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tGYo1THIIUke",
        "executionInfo": {
          "elapsed": 460,
          "status": "ok",
          "timestamp": 1688437676487,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "f339ef35-2fb7-4613-88e7-0209fa82914b"
      },
      "source": [
        "# 보너스 코딩: 다른 예문으로 추가 코딩\n",
        "# 토크나이징\n",
        "input_ids = tokenizer.encode(\"Covid19 delta is spreading\", return_tensors='pt')\n",
        "\n",
        "# max-length 값을 50으로 설정\n",
        "greedy_output = model.generate(input_ids, max_length=50)\n",
        "\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "Covid19 delta is spreading the word\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 24"
      ],
      "metadata": {
        "id": "VzYLeXtVxVca"
      }
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OtNVbaLtbvTH"
      },
      "source": [
        "# 코랩 메모리가 clear된 경우만 transformers 재설치\n",
        "!pip install transformers"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 752,
          "referenced_widgets": [
            "c2d670c56f4e43dca0b1fbb4a25963a5",
            "140355ab05e944adb082a531fc221c2a",
            "3d0ee8c59bbe45f1b2d7f261fa0b3378",
            "8c4de0c767a248fcb4f9c1c403e6b32c",
            "7f5aa68964e14554a6f46b23c8a31add",
            "7aa30f18dd0345818197be0af15a782a",
            "04a8388eb3264937ab859f1609214499",
            "701557c0046c4da7aa4c42c6b06b319c",
            "820e8b54bc9d4c8c926ca02a9e9ec5cc",
            "a9abf56f47a3496c932065e2a428d8b7",
            "5ec5ab93a94349ac9f7ce152f7282ad3",
            "25ab931cb052470fac0450ba26ec766e",
            "340dcb1598544223a236bf769333a60f",
            "195d3229b4c44ad7802d67eec2ef005c",
            "ade920ae7a1b4cc686c7b11b3957c8ef",
            "f86fb273276f475bbf12e87f7dc12a8c",
            "d0e96741457a490ea609e16c00c83d9f",
            "df57071c9a614617bdeafb29fe6edd86",
            "00b613133acd46d8a44c590848136083",
            "f8e31329dff344489f2d97a5ff258863",
            "e642d408e9bd4cb4a5c77f4e249fffda",
            "95b1529fb4f74aaab627a0411b306305",
            "47ae9fd6b082469d91159ae45a7507a2",
            "f9ebaf1351404afa94538580e8c04b0c",
            "ae36096e320642cfb7aa787d6025d6c7",
            "b7cf76c438c54defa42f576807572c4b",
            "bdfba0beb4d7435daae325e935bceb30",
            "330448aefb2f4988a7b53e0117ad915f",
            "60e51403506a4abc906242c603e5a127",
            "ab6ce94533d24472a2600648663d2a80",
            "f85a3db7473d45efa381ab31b23244df",
            "3d747714f47c44279fd55975996eb957",
            "dcb00892f8174891ad2006bc4afa9a53",
            "7415f7dec38f43f3b4dc22984c2f83ba",
            "42888ed6711c410382a3444839a5f3ad",
            "412dac7fde4a437083bb8720cf941a54",
            "0be4c507c536448da7e4286d9989f04c",
            "ee33135e027946da92c79fbee19d144d",
            "4d7a26eaa119451a92ed0d86a57eb10d",
            "ede4fa4a21324d48a925b66ef5e76820",
            "ebfd89bb00ff431ebf2f6e3d9c597392",
            "abd346854b0e441183c6ff7b7a68fd5d",
            "3c8e38cf30244e629594e7ea863ad695",
            "1d1233dcf1f54966b28f73abcaa4f7fa",
            "7a5c706b17c84466a5ae191d560b628c",
            "63447529de074727ad341bc152cd0097",
            "5e4f908e14244f58ad3a357c43de1420",
            "42e22ac502a94db9906aac01639c6d17",
            "f8791f4372754c0bbb72c79d6433e92a",
            "40847f9065984179803ec4fe91ba55e9",
            "8512c9347dbd4926aeb8f2bf65d4d4dd",
            "41988ef276c34c6a86dcfa015be58930",
            "4e6a7ed884fd43eba33406f3edc2e71c",
            "ae3fd8fcb01f4d78bb23bd241550faf8",
            "6001b60417c74a3797cefb791572608f"
          ]
        },
        "id": "KTEjg25XUgWl",
        "executionInfo": {
          "elapsed": 9842,
          "status": "ok",
          "timestamp": 1688438433912,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "4b299f75-6dab-47aa-d75e-8271c50c7700"
      },
      "source": [
        "# transformers 라이브러리에서 pipeline 불로오기\n",
        "from transformers import pipeline\n",
        "\n",
        "# pipeline에 과업(fill-mask) 및 모델 지정\n",
        "unmasker = pipeline('fill-mask', model='bert-base-uncased')\n",
        "\n",
        "# pipeline을 인스턴스화한 변수 unmasker에 [MASK] 토큰을 지닌 입력문장 투입\n",
        "unmasker(\"MLM and NSP is the [MASK] task of BERT.\")\n"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c2d670c56f4e43dca0b1fbb4a25963a5"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "25ab931cb052470fac0450ba26ec766e"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "47ae9fd6b082469d91159ae45a7507a2"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7415f7dec38f43f3b4dc22984c2f83ba"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7a5c706b17c84466a5ae191d560b628c"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.257278710603714,\n",
              "  'token': 2364,\n",
              "  'token_str': 'main',\n",
              "  'sequence': 'mlm and nsp is the main task of bert.'},\n",
              " {'score': 0.20740698277950287,\n",
              "  'token': 3078,\n",
              "  'token_str': 'primary',\n",
              "  'sequence': 'mlm and nsp is the primary task of bert.'},\n",
              " {'score': 0.06773308664560318,\n",
              "  'token': 2034,\n",
              "  'token_str': 'first',\n",
              "  'sequence': 'mlm and nsp is the first task of bert.'},\n",
              " {'score': 0.06548508256673813,\n",
              "  'token': 2430,\n",
              "  'token_str': 'central',\n",
              "  'sequence': 'mlm and nsp is the central task of bert.'},\n",
              " {'score': 0.061674028635025024,\n",
              "  'token': 3937,\n",
              "  'token_str': 'basic',\n",
              "  'sequence': 'mlm and nsp is the basic task of bert.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kUzmXu5kbX3k"
      },
      "source": [
        "# 25"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 678,
          "referenced_widgets": [
            "81c1adadf5054926abb0e7edc0d8e495",
            "fdcfae11993a426fbb06d6aad241df3c",
            "2a7b9f4456f04f2187a3e1bcd2eace9b",
            "fd726e1f312a4645a2bc80cbde5a0f2f",
            "a7be0c49059441bba50d7f2141671c35",
            "6782cc6ff7854a6bbfd48d3aee7e0639",
            "53f6e19936fc4a15900a487168c5afff",
            "1d5d10b588af42ba923f32d00492b0b4",
            "3d5848c0d99e467e8514a9099fc4d41c",
            "16a27c100f344deeaec2c0f6a4e8c9b8",
            "b5e6b3d75e2241eb8c1317c3eb528a8e",
            "21d4aecad2504b2b854755040f31d0a4",
            "ec1fe1ccddf04b99add11ceb9b421797",
            "2323a1b10f5d4eeba0faeba982486992",
            "fcc6cc7a74814d16a532f7c1eb3bb281",
            "db1f6872a5564b75bb6f3f7a6fd4119d",
            "e5c72086298044cf88f4297e61f82305",
            "955e4f0196f847c8bec534c7c6b1014b",
            "89c3e7470f7244ed843f176eb027e5db",
            "149c8da0fbce43cab419909f27fbb061",
            "d27071598efd4090b9a1ae0521f2a1f3",
            "fd66ba9429a747129847734ea201ef04",
            "5188962ff47f46ba9f11c7a9c7cf6add",
            "633b39fb0cf94a0cb36cfba286d4130a",
            "32f6b43e186e4f19b2f5e094ed7a4e40",
            "2695e9ecb5da42818435a18c4bccfaae",
            "e45d5ff4b55646caa7c197013de24016",
            "65ea31f948564d55894038122a76af9e",
            "f6d5a5020332411dbbc592c744a6ac10",
            "8613958a41d242cd8fe235fc6673c746",
            "e89bb5ff3844443fba63a9b7ca849d43",
            "867ae218c96b41c2836e4ee1f645264d",
            "f4855dd10474488798da968a4b8038ea",
            "8aeb39f6284f4d7ab2b632ae48f95155",
            "1f7d5ca15f434de0a1ccddc8287cd953",
            "950c3f9d37924c76b7bc174d176741c6",
            "edaac8da1a514948937f0221610f1416",
            "475f8ffe52aa499aa8c49f6d0620a541",
            "63cb0dc550ff453c90d65cb85cf96225",
            "ddab4bb3f7cc42a8bfa9798b0da3ed02",
            "af422412c8f94ef3995016004d15cf3c",
            "a9d7ad0cff68426db2212f15112c68d3",
            "0614efee37854c37993fa0caa09d5761",
            "bf923e06a78341fd82b64882b1199c7d",
            "7185a079d097414ea7dff33c561aea99",
            "37fcef4654fc403bb1d054bd4c2172e1",
            "2ed0f8a78f484a04a0c6d7f73a405749",
            "8f58dc55b6fa47148cd674f1c30cf827",
            "5b021ff5a7364b0d8ccfaada34d70486",
            "0ae510c0ab624178bde875735705c7e7",
            "c40bac2e247244deaed362abb205c3fe",
            "afb376fc36764b4197b4d6a5a2c9f236",
            "2686e2c6fc664e3aa2424e971fc6792a",
            "b2af0b5c2b5b472fa88f86392e306939",
            "da99d1a479fa4a809cb74193dbeaec83"
          ]
        },
        "id": "Kq7LqBATzKlu",
        "executionInfo": {
          "elapsed": 6433,
          "status": "ok",
          "timestamp": 1688438455429,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "ea86e581-ddba-4a74-d179-4bd8e6cfaa94"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 모델명이 바뀌었음에 유의\n",
        "unmasker = pipeline('fill-mask', model='distilbert-base-uncased')\n",
        "unmasker(\"MLM and NSP is the [MASK] task of BERT.\")\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/483 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "81c1adadf5054926abb0e7edc0d8e495"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/268M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "21d4aecad2504b2b854755040f31d0a4"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "5188962ff47f46ba9f11c7a9c7cf6add"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "8aeb39f6284f4d7ab2b632ae48f95155"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "7185a079d097414ea7dff33c561aea99"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.2590242922306061,\n",
              "  'token': 3078,\n",
              "  'token_str': 'primary',\n",
              "  'sequence': 'mlm and nsp is the primary task of bert.'},\n",
              " {'score': 0.163099005818367,\n",
              "  'token': 2364,\n",
              "  'token_str': 'main',\n",
              "  'sequence': 'mlm and nsp is the main task of bert.'},\n",
              " {'score': 0.08182773739099503,\n",
              "  'token': 4563,\n",
              "  'token_str': 'core',\n",
              "  'sequence': 'mlm and nsp is the core task of bert.'},\n",
              " {'score': 0.040237803012132645,\n",
              "  'token': 7037,\n",
              "  'token_str': 'dual',\n",
              "  'sequence': 'mlm and nsp is the dual task of bert.'},\n",
              " {'score': 0.024844937026500702,\n",
              "  'token': 4054,\n",
              "  'token_str': 'principal',\n",
              "  'sequence': 'mlm and nsp is the principal task of bert.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y_Zb__OPc6ew"
      },
      "source": [
        "# 26"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 618,
          "referenced_widgets": [
            "4374d00aa1ed499e95dd1d89a3f1b899",
            "416133581a0d4f86bc0b5bf30a0c928f",
            "b0766606f7b64bce9e851937bd3e5e23",
            "79b6ae237c944a9887ffbae4a4e403a5",
            "6461bc6484d1474294eb34607678e669",
            "ac35b6f440b041ee9961a7de1222a58e",
            "765d8d3813e64e8c9aa750910d30456d",
            "708170842c1740109dc0abef2d09c23f",
            "94bcad1280df4e6daecaef542bada223",
            "172072f23a5f4003a715bc07fcc7cd14",
            "00db136d7c6d4bb789c26a4ad9d923b0",
            "59c929f0b85a45f3b4c378284e9267c9",
            "7a41d1f2d86c4b859c7ee8ada61b64ce",
            "d6a9b53abe0a4fa784d3cc7b8dda4e85",
            "c62619c4b7ff45a583605e6bb5d567ea",
            "1a003573df9842ba958b0c2bb2e7bbb0",
            "528ac36c02de487f83268917e0db8103",
            "86e28309edcd424bb1cb865b6ec3ccc1",
            "9445fbce0f824977b773a406e25e0dc4",
            "438fe0918f7c40b0ac157f9a08fb256c",
            "e11cd2e186ed4d2b88e6657e94fe7d1e",
            "82e6416e5db3401a8777062d53a07935",
            "d9c0c8759c4547a4ab59968dec2e9a97",
            "6c05d86293b14f09a6d0695792cfa238",
            "816147b5db8d4c62b1644f0332f24e9e",
            "a3d798197bf34241ad0c752f04d98575",
            "593c5bd58e284a5ea5c4013d4ef5b83f",
            "7446cd5392364341839e7dc66e70ca09",
            "a29c2cd777d141d1b42140211c90c748",
            "e6ff9a8d37634a6bbf67b13f0a7c1a78",
            "175dfddb46ce498c96b873036f4b8a68",
            "fcdbb725bb764ad28a4a2181a5a2979d",
            "1100d5a0251f48ea9fb2b69a854cf890",
            "e9c1b545e456471ca6bb275e75887591",
            "4ff9da5b885f4a81b876cdeab42f4ee1",
            "5a903525b5fa4e808cfb112e3a640c49",
            "f87dcbb01fdc432ba57554e55bcd12d0",
            "824150bf540143d280a7e6b59318a836",
            "facd9e6ed87249fc9d6326d544d95b27",
            "e03801d37e664d3ca6d14f7afe320d52",
            "a3071dd8242d4c2e9a0d25b8c9fa75b2",
            "5289ff7de3394a46a2ddb613963e0a3e",
            "bbc427a6e46144969cba43c831d13d9b",
            "7fc3b5c1630542c492c6c2a095b931d4"
          ]
        },
        "id": "011u_S5DbtBE",
        "executionInfo": {
          "elapsed": 4902,
          "status": "ok",
          "timestamp": 1688438467208,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          },
          "user_tz": -540
        },
        "outputId": "02f062d6-dd5b-4e4c-cfb6-8aea4a430a6c"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "# 모델명이 바뀌었음에 유의\n",
        "unmasker = pipeline('fill-mask', model='albert-base-v2')\n",
        "unmasker(\"mlm and nsp is the [MASK] task of bert.\")\n"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/684 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4374d00aa1ed499e95dd1d89a3f1b899"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/47.4M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "59c929f0b85a45f3b4c378284e9267c9"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)ve/main/spiece.model:   0%|          | 0.00/760k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d9c0c8759c4547a4ab59968dec2e9a97"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.31M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e9c1b545e456471ca6bb275e75887591"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'score': 0.04760127514600754,\n",
              "  'token': 6612,\n",
              "  'token_str': 'ultimate',\n",
              "  'sequence': 'mlm and nsp is the ultimate task of bert.'},\n",
              " {'score': 0.024472327902913094,\n",
              "  'token': 20766,\n",
              "  'token_str': 'hardest',\n",
              "  'sequence': 'mlm and nsp is the hardest task of bert.'},\n",
              " {'score': 0.023495247587561607,\n",
              "  'token': 1256,\n",
              "  'token_str': 'primary',\n",
              "  'sequence': 'mlm and nsp is the primary task of bert.'},\n",
              " {'score': 0.021575260907411575,\n",
              "  'token': 407,\n",
              "  'token_str': 'main',\n",
              "  'sequence': 'mlm and nsp is the main task of bert.'},\n",
              " {'score': 0.018088163807988167,\n",
              "  'token': 18369,\n",
              "  'token_str': 'foremost',\n",
              "  'sequence': 'mlm and nsp is the foremost task of bert.'}]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    }
  ]
}