{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [
        {
          "file_id": "1hcJkcxDH0A2yNCJ0EuitC1ycrvffOwUQ",
          "timestamp": 1667701126583
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hYc-LB0bbUI2"
      },
      "source": [
        "# 82"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ulOdaNoa1PY",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "c80ed4b0c230494ba19297149539207f",
            "f61b6eb7b37147d183544e257a112fd9",
            "ea9dc911e5bf48d6857841806c5e4ad9",
            "a2f53eb203dd4e50bb870643d39ba976",
            "6802d0a2b6a54e0da929ff745e8a7250",
            "4be4961a69c440aaa299cf6349fd65c4",
            "3b0afdb21e8d49b9bc0793d5c4a8fe21",
            "f1cb06b0876240f2b57e80d66249641d",
            "69ef04662482481e98677820d97b6379",
            "29b075d050894527b3ca74f4af7bb3f8",
            "057544b22371424da96b42c9073169e4",
            "528b46f169da4253bb18c8fe54e46728",
            "309e25124b7a46a59860bb9fa897e425",
            "ee8eaa6d6472432199148e31c102fd84",
            "44465c59f44c4b42ab2e8e04f1633735",
            "eca76c69f8bd4ca2956f8ce7cc65bbe9",
            "2aec7bb3b6e642c88bc525e4609008a0",
            "7316b70d82c141b2bc3e0c0e8b43a119",
            "3d5f8c473ae046a999ee2e2eb1654155",
            "4325a2008c844e5eb3d887ad74ab4eb0",
            "ac2c832bad074b50bb7edf8e3a4fa422",
            "584ec607ad6442f1a0285be263a873ac",
            "ea92c51c328742fa9655351253cb67e8",
            "969e26c5e51c45a094f721170b61e3ad",
            "c6e5c9502c7e47bba68bfdc97204289d",
            "7d87f376f4684c6191c59b306e8892a1",
            "18a7e722bd9a4aee9c04edded329d783",
            "340f5bcf886c468788dcf2db33c2ec8e",
            "848091996c284c4480f69abbb0fadd54",
            "5afcded868ac464b8649d60e094cce67",
            "53510ba030324076b1660f12f262e36b",
            "6eca22bc0a7441bdb6620bf4913e1daa",
            "273b7df61dfc41388feb8096a15e6793"
          ]
        },
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455546686,
          "user_tz": -540,
          "elapsed": 37776,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "08ea5c9c-7592-4890-cf3a-cf8f106dc60d"
      },
      "source": [
        "# 런타임 30초 소요\n",
        "!pip install transformers\n",
        "!pip install sentencepiece\n",
        "from transformers import MobileBertTokenizer, MobileBertModel\n",
        "import torch\n",
        "\n",
        "# 모델 및 토크나이저 불러오기\n",
        "tokenizer_mbert = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
        "model_mbert = MobileBertModel.from_pretrained('google/mobilebert-uncased')\n",
        "\n",
        "# mobile_mbert 모델 구조 출력\n",
        "model_mbert\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting transformers\n",
            "  Downloading transformers-4.30.2-py3-none-any.whl (7.2 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/7.2 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.3/7.2 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/7.2 MB\u001b[0m \u001b[31m27.6 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m69.7 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.2/7.2 MB\u001b[0m \u001b[31m50.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.12.2)\n",
            "Collecting huggingface-hub<1.0,>=0.14.1 (from transformers)\n",
            "  Downloading huggingface_hub-0.15.1-py3-none-any.whl (236 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m236.8/236.8 kB\u001b[0m \u001b[31m20.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.22.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.27.1)\n",
            "Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers)\n",
            "  Downloading tokenizers-0.13.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m42.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting safetensors>=0.3.1 (from transformers)\n",
            "  Downloading safetensors-0.3.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m54.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.65.0)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.14.1->transformers) (4.6.3)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Installing collected packages: tokenizers, safetensors, huggingface-hub, transformers\n",
            "Successfully installed huggingface-hub-0.15.1 safetensors-0.3.1 tokenizers-0.13.3 transformers-4.30.2\n",
            "Collecting sentencepiece\n",
            "  Downloading sentencepiece-0.1.99-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m16.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: sentencepiece\n",
            "Successfully installed sentencepiece-0.1.99\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c80ed4b0c230494ba19297149539207f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/847 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "528b46f169da4253bb18c8fe54e46728"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading pytorch_model.bin:   0%|          | 0.00/147M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ea92c51c328742fa9655351253cb67e8"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.decoder.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing MobileBertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MobileBertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "MobileBertModel(\n",
              "  (embeddings): MobileBertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 128, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 512)\n",
              "    (token_type_embeddings): Embedding(2, 512)\n",
              "    (embedding_transformation): Linear(in_features=384, out_features=512, bias=True)\n",
              "    (LayerNorm): NoNorm()\n",
              "    (dropout): Dropout(p=0.0, inplace=False)\n",
              "  )\n",
              "  (encoder): MobileBertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-23): 24 x MobileBertLayer(\n",
              "        (attention): MobileBertAttention(\n",
              "          (self): MobileBertSelfAttention(\n",
              "            (query): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (key): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (value): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): MobileBertSelfOutput(\n",
              "            (dense): Linear(in_features=128, out_features=128, bias=True)\n",
              "            (LayerNorm): NoNorm()\n",
              "          )\n",
              "        )\n",
              "        (intermediate): MobileBertIntermediate(\n",
              "          (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "          (intermediate_act_fn): ReLU()\n",
              "        )\n",
              "        (output): MobileBertOutput(\n",
              "          (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "          (LayerNorm): NoNorm()\n",
              "          (bottleneck): OutputBottleneck(\n",
              "            (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "            (LayerNorm): NoNorm()\n",
              "            (dropout): Dropout(p=0.0, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (bottleneck): Bottleneck(\n",
              "          (input): BottleneckLayer(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): NoNorm()\n",
              "          )\n",
              "          (attention): BottleneckLayer(\n",
              "            (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "            (LayerNorm): NoNorm()\n",
              "          )\n",
              "        )\n",
              "        (ffn): ModuleList(\n",
              "          (0-2): 3 x FFNLayer(\n",
              "            (intermediate): MobileBertIntermediate(\n",
              "              (dense): Linear(in_features=128, out_features=512, bias=True)\n",
              "              (intermediate_act_fn): ReLU()\n",
              "            )\n",
              "            (output): FFNOutput(\n",
              "              (dense): Linear(in_features=512, out_features=128, bias=True)\n",
              "              (LayerNorm): NoNorm()\n",
              "            )\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): MobileBertPooler()\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 951,
          "referenced_widgets": [
            "9bb7bf69ef454864b80f75631395a119",
            "b1aa1e1efc9d4559a01e974d0a20f516",
            "0cb312fdb0bc492e81ce3ee9f3eee0f8",
            "1de5c38b8dfe482ebccec61e3a5bcdba",
            "e7fd9824edab4d0fa2dfe5a11828d8b4",
            "ce88aff26cb04ef39350749f7e247499",
            "610df492abac44d6bd11fc37b93c6170",
            "c01e25846cce4dc6a16cb95dbad42028",
            "9e273b262e424ed2be2f76e26834ff30",
            "0a539c490bc347b3a657cecd06996943",
            "db272c39785b48a1820cecd5b9d486b2",
            "e6ae8eca2e274623b65e684e6cc54a64",
            "9855154a2bf346f187763ab1410b5f5a",
            "f95b539b7ce24eb586081d55c786c5c3",
            "63632021e27041b7877cd7c4112ffd64",
            "0beb56dbab1449318b8340186b122ec3",
            "4e6f7b3937424646ac663ce3520390f7",
            "8912bd1623ec49369c7e437eb4865b68",
            "1d2057552b5d4909bba24cb930eebf0e",
            "27df49e83c8b4ac3bd34a2a29bf8cb39",
            "37a5551338c84d4ab6d0475ad47c955f",
            "b690936cbceb40668bec329478c19eb2",
            "0eda810f38a44edcb3095cd9fdc28a2d",
            "82feee72b93141559ae2ab62b84ec345",
            "36ab1b4fddf44597a31c205c3af92b17",
            "5e22dd562d324bc1ac2d59f971eecea5",
            "2ca6bf1567954be68875206770e8a914",
            "bf3a13151e8e4c64b188664a599fc096",
            "d092fb0acdcb4347acb2bf9e26737ff0",
            "d9d9d8da1cb54f8ba1b40cb3060ee123",
            "b357adf342954dd6a47b55dd5a5d40c7",
            "0f9a97124de246308a9fabd4dde0e424",
            "e9f2c02fad594889a4629639091adb89",
            "6a1aea08c0c140fd9cc8be825cfc3546",
            "ce146762f5b346a2bdcfb44f2abcf91f",
            "37828a10d6e74af1899c4bd409bcc3e9",
            "19efb8e076434514a292080e0cd8cf82",
            "bcb0b32e3167475da2c74f65018deec5",
            "2390da4c684c407995143ef54152b6d4",
            "41a5c88998364692944c4ccc1fdc5941",
            "b8fa757776d942a69e775c828f934706",
            "c045e124ce4a4729a68d021b16298bc6",
            "5e505e3c97194fd7a9b8353a3cfe9303",
            "e2ca875a5faf44698ef7c97d15bccdc6"
          ]
        },
        "id": "49xOtvExbU4M",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455561422,
          "user_tz": -540,
          "elapsed": 7979,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "1276a683-07f1-4498-dae1-dae7362ad378"
      },
      "source": [
        "# 런타임 30초 소요\n",
        "from transformers import BertTokenizer, BertModel\n",
        "\n",
        "# 모델 및 토크나이저 불러오기\n",
        "tokenizer_bert = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model_bert = BertModel.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# mobile_bert 모델 구조 출력\n",
        "model_bert\n"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9bb7bf69ef454864b80f75631395a119"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e6ae8eca2e274623b65e684e6cc54a64"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0eda810f38a44edcb3095cd9fdc28a2d"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6a1aea08c0c140fd9cc8be825cfc3546"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.weight', 'cls.predictions.transform.dense.bias', 'cls.seq_relationship.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertModel(\n",
              "  (embeddings): BertEmbeddings(\n",
              "    (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
              "    (position_embeddings): Embedding(512, 768)\n",
              "    (token_type_embeddings): Embedding(2, 768)\n",
              "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "    (dropout): Dropout(p=0.1, inplace=False)\n",
              "  )\n",
              "  (encoder): BertEncoder(\n",
              "    (layer): ModuleList(\n",
              "      (0-11): 12 x BertLayer(\n",
              "        (attention): BertAttention(\n",
              "          (self): BertSelfAttention(\n",
              "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "          (output): BertSelfOutput(\n",
              "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (intermediate): BertIntermediate(\n",
              "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
              "          (intermediate_act_fn): GELUActivation()\n",
              "        )\n",
              "        (output): BertOutput(\n",
              "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
              "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
              "          (dropout): Dropout(p=0.1, inplace=False)\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "  )\n",
              "  (pooler): BertPooler(\n",
              "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
              "    (activation): Tanh()\n",
              "  )\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n8AhoYESbmsX"
      },
      "source": [
        "#83"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "04X31acmbndL",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455624585,
          "user_tz": -540,
          "elapsed": 3,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "fb4447ab-431d-4d41-f31e-894e54c19542"
      },
      "source": [
        "import torch\n",
        "text = \"Mobile bert is more practical than bert.\"\n",
        "\n",
        "# Mobile BERT 토크나이징\n",
        "inputs = tokenizer_mbert.tokenize(text)\n",
        "print(inputs)\n",
        "\n",
        "# BERT 토크나이징\n",
        "inputs = tokenizer_bert.tokenize(text)\n",
        "print(inputs)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['mobile', 'bert', 'is', 'more', 'practical', 'than', 'bert', '.']\n",
            "['mobile', 'bert', 'is', 'more', 'practical', 'than', 'bert', '.']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oynV_H_XblqP"
      },
      "source": [
        "# 84"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-MjL04jbXgv",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455628418,
          "user_tz": -540,
          "elapsed": 772,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "76a1654e-c9a1-4b85-d32b-7522ab1071ee"
      },
      "source": [
        "import torch\n",
        "text = \"Mobile bert is more practical than bert.\"\n",
        "\n",
        "# Mobile BERT 인코딩\n",
        "inputs = tokenizer_mbert.encode(text)\n",
        "\n",
        "# 텐서 토치 타입으로 만든 inputs의 첫번째 위치(0)에 1인 차원을 추가하여\n",
        "# Mobile BERT에 투입\n",
        "# me --> unsqueeze와 squeeze는 팁상자에서만이 아니라 왜 여기 이게 쓰이는지도 찾아볼 것\n",
        "outputs = model_mbert(torch.tensor(inputs).unsqueeze(0))\n",
        "\n",
        "# Mobile BERT의 출력물인 outputs의 최종 은닉층 차원 확인\n",
        "print(outputs.last_hidden_state.shape)\n",
        "\n",
        "# BERT 인코딩\n",
        "inputs = tokenizer_bert.encode(text)\n",
        "\n",
        "# 텐서 토치 타입으로 만든 inputs의 첫번째 위치(0)에 1인 차원을 추가하여\n",
        "# BERT에 투입\n",
        "outputs = model_bert(torch.tensor(inputs).unsqueeze(0))\n",
        "\n",
        "# BERT의 출력물인 outputs의 최종 은닉층 차원 확인\n",
        "print(outputs.last_hidden_state.shape)\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 10, 512])\n",
            "torch.Size([1, 10, 768])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rcrS7M3WenlN"
      },
      "source": [
        "# 85"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Mobile BERT 추론\n",
        "from transformers import MobileBertTokenizer, MobileBertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# 토크나이저 및 모델 불러오기\n",
        "tokenizer = MobileBertTokenizer.from_pretrained('google/mobilebert-uncased')\n",
        "model = MobileBertForMaskedLM.from_pretrained('google/mobilebert-uncased')\n",
        "\n",
        "# 마스크한 문장 및 정답 문장을 각기 토크나이징\n",
        "inputs = tokenizer(\"The capital of Korea is [MASK].\", return_tensors=\"pt\")\n",
        "labels = tokenizer(\"The capital of Korea is Seoul.\", return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "# 토크나이징 결과인 inputs(**kwargs 형식)와 lables를 모델에 입력\n",
        "outputs = model(**inputs, labels=labels)\n",
        "# 손실 추출\n",
        "loss = outputs.loss\n",
        "# 로짓 추출\n",
        "logits = outputs.logits\n",
        "\n",
        "# logits.argmax(-1)은 로짓 텐서의 마지막 축(axis)의 값들을 대상으로 argmax()를 적용\n",
        "# logits.argmax(-1) 실행 결과의 첫번째 원소가 logits.argmax(-1)[0]\n",
        "\n",
        "# 리스트 내포 [tokenizer.~.argmax(-1)[0]] 코드는\n",
        "# logits.argmax(-1) 실행 결과의 첫번째 원소안의 구성 요소들을 하나씩 변수 i로 추출하여 item()으로 파이썬 숫자화하고\n",
        "# 파이썬 숫자인 i.item()을 디코딩하고 빈 공백(스페이스)은 없앰\n",
        "\n",
        "# 리스트 내포는 for 반복루프가 있기 때문에 처리 결과가 반복적으로 발생하는데\n",
        "# 발생 결과에서 [1:-1]은 맨 처음 요소와 맨 마지막 요소를 제거\n",
        "# 이렇게 처리된 결과를 join()으로 순차적으로 저장 후 print()로 출력\n",
        "print(' '.join([tokenizer.decode(i.item()).replace(\" \", \"\") for i in logits.argmax(-1)[0]][1:-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GdK_zI8rAp6",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455639213,
          "user_tz": -540,
          "elapsed": 7356,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "af65a408-e0db-4d3d-e536-d8fce81e2688"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at google/mobilebert-uncased were not used when initializing MobileBertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing MobileBertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the capital of korea is seoul .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# BERT 추론\n",
        "# Mobile BERT 때와 비교하여 토크나이저와 모델이 다름\n",
        "from transformers import BertTokenizer, BertForMaskedLM\n",
        "import torch\n",
        "\n",
        "# 토크나이저 및 모델 불러오기\n",
        "# Mobile BERT 때와 비교하여 from_pretrained() 괄호안 모델이 다름\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\n",
        "model = BertForMaskedLM.from_pretrained('bert-base-uncased')\n",
        "\n",
        "# 이하 코드는 Mobile BERT와 동일. 코드 설명은 해당 코드 참조\n",
        "inputs = tokenizer(\"The capital of Korea is [MASK].\", return_tensors=\"pt\")\n",
        "labels = tokenizer(\"The capital of Korea is Seoul.\", return_tensors=\"pt\")[\"input_ids\"]\n",
        "\n",
        "outputs = model(**inputs, labels=labels)\n",
        "loss = outputs.loss\n",
        "logits = outputs.logits\n",
        "\n",
        "print(' '.join([tokenizer.decode(i.item()).replace(\" \", \"\") for i in logits.argmax(-1)[0]][1:-1]))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zOh95ZqRM4wU",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455651183,
          "user_tz": -540,
          "elapsed": 6075,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "b2a20fca-d546-463e-fda1-df4cae5c1600"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.weight', 'cls.seq_relationship.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "the capital of korea is seoul .\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCbrLPM8fHBy"
      },
      "source": [
        "# 86"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265,
          "referenced_widgets": [
            "d44496edc1994525b29bf133a09428cb",
            "f50bcafe5d5a4eeab18fcbd347813579",
            "b41beab5c5274898b8596281a261e1f3",
            "4541539494ff41a1a3239a081db43467",
            "c3360a62b2de4a0288381a73fd312312",
            "4afcffcf2663466fa51515952f26b77a",
            "f18d479613e149b2a703dc5d2505025a",
            "7b2d213cfe75428bb45076cf2d59c52d",
            "6a88f98aa9b74009a345480421301ab2",
            "a4ea18558028425f96f7b55af3d8db6a",
            "3f879564a0da47aea8662b5c753293ba",
            "002d76b6a637423a8f7c4e111aa03d90",
            "d0ef9df00d70403f88a7725a75492524",
            "05c3b446eb1f4855932a1c919c970509",
            "21f958ba858141e388fd112591ee726e",
            "7cbe3a64a84d4a54b7ec9c6feccf129a",
            "6198a8bf39d249f5a5b6e940ca57bc4b",
            "37458f1a7ce947358b31feff0a088be9",
            "fb18ca2fa95047c0a92b3c7a470124b7",
            "2b4874acc5074200a3d23294aa3585ef",
            "3316c1c322474212a405a51d7f0200fa",
            "54853727f100452ea710699459bf3e55",
            "42d23d2dbf2c4c74a314046c64c83d18",
            "5edee292f5ab42b88ae8d07fa5e44f0c",
            "4e0985c3753242f0bc84bac1a31909ef",
            "c5935f72f91a4e8498400ac8561f04b2",
            "cbf0dee858a34efbbd34a5276ec608b7",
            "deaf82243b0d45ca90e55aed948629f3",
            "ccb045971fa34ceebfc275c0b02e0ae5",
            "a994e3dcdc044521ae1072edb5840330",
            "9d15a908ca074521890b8dc85099ed2a",
            "79a7b9a09f104381a55abea1f2571e2c",
            "4eaf0560cbde4b5197e567b2e0a36ec7",
            "9ffd39b53554404c8dd5c7db4dcc1091",
            "4b0523c2a6c14098a6c4e8ca395c4056",
            "105a0cd3a3a2486bb51ffb4ca574fb58",
            "5eca19cfd7924276916aa92a835841a6",
            "e26e9eb96a70440e888b5fd4988f1701",
            "5e0d70f11fbe414f8786d4b74c4fdd92",
            "c8b7967d2d104d6797b7fa123ffbe091",
            "0bbd767bf6a64c52891cd4b1d9e91f9a",
            "db53fc432089461aa7378f2662a99ea5",
            "965b36f46e3748b4a146e6261045b38b",
            "24937f2dba8a4ef6a11deaef4ca77279",
            "4a0c8d7255a7465bb5a3972453a26a3a",
            "1c746107c8854760946345e5aeaaa135",
            "2e56c18021424e159c118488aed8ec1d",
            "726910f8f4ab4430ac188f9e2269eec6",
            "2edc786e1e394b4cb4b8d94a6f77c96e",
            "548833c1efdf48b8ac3662d0d6e4a14e",
            "a0ddd0907aa04c9884bedcb2a229a681",
            "b045a9dc3e0349f484d77004d07e014e",
            "1a0008b7cc99404593e2f46ed15bdcaf",
            "5419e00c3a8f447f99328a04994a733f",
            "0e13946576734868bcd66cde89a96e05",
            "63e1aef361664cfb989856fa3ee4dd0c",
            "a1b6b526c15541dc9dc5c1a121ffa808",
            "a6fcb6af8327406fa6e530dcfedaa07e",
            "657d36ee077642f18bf5099d699e4c29",
            "ac4f0046bac84fc097508aa01e0cc94e",
            "beb8dc0c5810434f8fe02e0a958ea639",
            "da3d48b5fcfb49baa5d70d765c74395f",
            "c231a3b4cd3a4e0e9e632112a55c8bd0",
            "ca75bdbed99546af95f91576e5fa68ec",
            "582dc031bcb640c2ab173e14c3a4a8b1",
            "bed7bca980794edbafc24ef8b0a470a1"
          ]
        },
        "id": "Wsypn4oVf-in",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455667387,
          "user_tz": -540,
          "elapsed": 6390,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "2e5ef856-7ee9-475d-d093-39167c70e95d"
      },
      "source": [
        "# 코랩 메모리가 갱신(clear)되었을 경우만 트랜스포머스 라이브러리 재설치\n",
        "#!pip install transformers\n",
        "\n",
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# 토크나이저 및 모델 불러오기\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"distilgpt2\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"distilgpt2\")\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/762 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "d44496edc1994525b29bf133a09428cb"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "002d76b6a637423a8f7c4e111aa03d90"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "42d23d2dbf2c4c74a314046c64c83d18"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/1.36M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "9ffd39b53554404c8dd5c7db4dcc1091"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/transformers/models/auto/modeling_auto.py:1362: FutureWarning: The class `AutoModelWithLMHead` is deprecated and will be removed in a future version. Please use `AutoModelForCausalLM` for causal language models, `AutoModelForMaskedLM` for masked language models and `AutoModelForSeq2SeqLM` for encoder-decoder models.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/353M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "4a0c8d7255a7465bb5a3972453a26a3a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "63e1aef361664cfb989856fa3ee4dd0c"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "orEhiahggBKz"
      },
      "source": [
        "# 87\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ftmexqRMgCUZ"
      },
      "source": [
        "[Check exBERT](https://huggingface.co/exbert/?model=distilgpt2&modelKind=bidirectional&sentence=The%20girl%20ran%20to%20a%20local%20pub%20to%20escape%20the%20din%20of%20her%20city.&layer=5&heads=..0,1,2,3,4,5,6,7,8,9,10,11&threshold=0.7&tokenInd=null&tokenSide=null&maskInds=..&hideClsSep=true)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lg5QYukxgMYF"
      },
      "source": [
        "#88"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Qb0uOYCeoMd",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455692965,
          "user_tz": -540,
          "elapsed": 287,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "cb04d667-d2c9-43bf-fe52-ee1672b15ac1"
      },
      "source": [
        "\n",
        "# 입력 문장을 토크나이저로 인코딩\n",
        "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
        "\n",
        "# 최대 출력 단어를 12개로 설정하고 문장 생성\n",
        "greedy_output = model.generate(input_ids, max_length=12)\n",
        "\n",
        "# 문자열(Output:)를 출력 후 한 줄 띄고 막대(-)를 100개 출력하여 점선 출력\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "\n",
        "# model.generate()의 출력 결과물 greedy_output의 첫번째 요소를 디코딩\n",
        "# [CLS], [SEP] 등 특수 토큰의 디코딩 제외\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I like gpt because it's a good thing to have\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cou_MmngcGl"
      },
      "source": [
        "# 89"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209,
          "referenced_widgets": [
            "e28900afc69943f19e7c0fd3f1a2623a",
            "adb00c852ff04394a9c8042b85374408",
            "2cfaff09189f4a069483a0ee6ada9d9e",
            "2fcad2f9944143dcaba2a07c78244f4b",
            "bbdbf7e3305c423189447f6a90e49c7c",
            "6273c2dc437d4917b99107db462fd7c1",
            "b6b14bc6e5f9481b887ca29f6f99a1d7",
            "55cf018a95f9440893282eb4053dbc00",
            "28589957c23f48e5a68f113a9920a6a7",
            "253fb16a14774c17abf1a3bbeda3e870",
            "81a91dc7979b4b2f87a5e2fef9135fb8",
            "ed4ea95b421e44b3a220abcf2a4c168f",
            "287b16604e2246ed8241a3893ed932c2",
            "96632fb4b8ce410ebddf41bcda569ae9",
            "02fb3d531e8245e8a9dc008ed174ad24",
            "0545019daec44da0841ab3d9ccada90c",
            "b7469d06067f4b21b119a1545593cf6c",
            "d72576cb30664f18a60cc1e2ec9e044b",
            "2c610375e69f46c986143af7b65f55c7",
            "42015b0917574d07bb63c12bae61173b",
            "54c3d08688bf4f4f94beae0462e7eea7",
            "3964e1c8f7814524853ba014bc314b30",
            "c4fe763187be4a71b8bf0ee3cce67c70",
            "a942307f02e94c298e2b0dd92b6f45f0",
            "d7ef99b7af494766a73f9e05150ed532",
            "7b1ede89f32048f98df722f3e99c7747",
            "3fd614168236478980cbbbad47b11e2c",
            "de36a760e49640b3b98ae40f868c1ec6",
            "d082221643314e12a6b81febe4b3459c",
            "13d40b79ce5c47619e747f7b82a83572",
            "3fcdf562903849e6ac0505d575ae4ed8",
            "504d27913000495cb462a9134b0529ce",
            "65ebde435472463e8d8d2169b8732808",
            "0b4b547f5fbc4ef6b3a73caa21bdc688",
            "2d3ef07b7f7e4e9fa513ce6013a597b7",
            "466ad4f6412844b6b1b1a2f5047fae1d",
            "ea0fb479ec414465ae240dcbb9e59527",
            "db50cf778a794a81b96347b1f61dd614",
            "880726cf0e2741e798c6eecdcb21ba40",
            "fba44399aa9544c1a02e00bbcf3f4382",
            "b0704310fa1947d1a80e93a75b7a96a2",
            "52d61ab436664e628abf56f0a3f118ba",
            "3ae51f05b4f64ba2bec96732aac13bf0",
            "3b77db0d70d241fb8e3940dd68b54eac",
            "35e93981ae19447d8de748e7388be7b6",
            "0c63f656f8624374b1fbdba93f079ead",
            "60b5d8dc5c3d4d85939d27f63b2c667c",
            "fa765b6d213f4cc884a6166b9e922765",
            "cd25e491f80b416d975a0ea9c93be461",
            "26b3da437b0043d4bdc356160ac237f9",
            "340b138a1f1642ac9bb14df744b0cd9d",
            "184e81169fb44976bda627b9de0a7218",
            "674d79712376414096990136eba2ddda",
            "d77ead4c730e4c73948de1c70a456dbe",
            "667553b2d3dd4e8382a1784e347ae8aa",
            "6c978271b05d4ae0a6051d2507c0fbfa",
            "c322bb275568408eac6f446988f6682a",
            "3cf94ed3d20d44979078f23d3ac26306",
            "6e06ff6aad4c42c094a862de69386d82",
            "9e0d3c41d6e149708b4f03635a203850",
            "6801ef51693349078a2cf9389734ceea",
            "a70e3df707ba4316a2ca962bb02096d7",
            "eab7383a73a843b4bc7ef64234966115",
            "984ee6d4f7b140529485bd2ea70f4702",
            "b5ea375bf7e640aeb7bad9e3f1d8e294",
            "98c70cdb19a94b13854a714f45eb2000"
          ]
        },
        "id": "LoGTnxL7f7FI",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455709369,
          "user_tz": -540,
          "elapsed": 10372,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "7287915a-e288-405e-bdcb-1dcadaa5f135"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelWithLMHead\n",
        "\n",
        "# 토크나이저 및 모델 불러오기\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"microsoft/DialoGPT-small\")\n",
        "model = AutoModelWithLMHead.from_pretrained(\"microsoft/DialoGPT-small\")\n"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/26.0 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "e28900afc69943f19e7c0fd3f1a2623a"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/641 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "ed4ea95b421e44b3a220abcf2a4c168f"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/vocab.json:   0%|          | 0.00/1.04M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "c4fe763187be4a71b8bf0ee3cce67c70"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "0b4b547f5fbc4ef6b3a73caa21bdc688"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/351M [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "35e93981ae19447d8de748e7388be7b6"
            }
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Downloading (…)neration_config.json:   0%|          | 0.00/124 [00:00<?, ?B/s]"
            ],
            "application/vnd.jupyter.widget-view+json": {
              "version_major": 2,
              "version_minor": 0,
              "model_id": "6c978271b05d4ae0a6051d2507c0fbfa"
            }
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWQQXKpvg2N0"
      },
      "source": [
        "# 90"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4eKpqC6UgcuH",
        "executionInfo": {
          "status": "ok",
          "timestamp": 1688455717989,
          "user_tz": -540,
          "elapsed": 1482,
          "user": {
            "displayName": "Jason Book Yim",
            "userId": "02824935638305274154"
          }
        },
        "outputId": "28e69095-9efe-4681-8f53-83687c3139d5"
      },
      "source": [
        "\n",
        "# 입력 문장을 토크나이저로 인코딩\n",
        "input_ids = tokenizer.encode(\"I like gpt because it's\", return_tensors='pt')\n",
        "\n",
        "# 최대 출력 단어를 30개로 설정하고 문장 생성\n",
        "greedy_output = model.generate(input_ids, max_length=30)\n",
        "\n",
        "# 이하 코딩 설명은 문제 88 참조\n",
        "print(\"Output:\\n\" + 100 * '-')\n",
        "print(tokenizer.decode(greedy_output[0], skip_special_tokens=True))\n"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Output:\n",
            "----------------------------------------------------------------------------------------------------\n",
            "I like gpt because it's a good way to get a feel for the game.\n"
          ]
        }
      ]
    }
  ]
}